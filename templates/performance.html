{% extends "base.html" %}

{% block title %}Model Performance - Malicious Node Detection{% endblock %}

{% block content %}
<div class="container">
    <div class="row">
        <div class="col-12">
            <h1 class="mb-4">
                <i class="fas fa-tachometer-alt text-primary"></i>
                Model Performance Comparison
            </h1>
            
            {% if metrics %}
                {% for target_name, target_metrics in metrics.items() %}
                <div class="card shadow-sm mb-4">
                    <div class="card-header bg-primary text-white">
                        <h5 class="card-title mb-0">
                            <i class="fas fa-target"></i>
                            {{ target_name.replace('_', ' ').title() }} Classification Results
                        </h5>
                    </div>
                    <div class="card-body">
                        <!-- Performance Metrics Table -->
                        <div class="table-responsive mb-4">
                            <table class="table table-striped table-hover">
                                <thead class="table-dark">
                                    <tr>
                                        <th>Algorithm</th>
                                        <th>Accuracy (%)</th>
                                        <th>Precision (%)</th>
                                        <th>Recall (%)</th>
                                        <th>F1-Score (%)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    {% for algo_name, metrics_data in target_metrics.items() %}
                                    <tr>
                                        <td class="fw-bold">
                                            {% if algo_name == 'knn' %}
                                                <i class="fas fa-users text-info"></i> K-Nearest Neighbors
                                            {% elif algo_name == 'svc' %}
                                                <i class="fas fa-vector-square text-warning"></i> Support Vector Classifier
                                            {% elif algo_name == 'nb' %}
                                                <i class="fas fa-brain text-success"></i> Naive Bayes
                                            {% elif algo_name == 'STT' %}
                                                <i class="fas fa-tree text-primary"></i> Stacked Tao Tree classifier
                                            {% endif %}
                                        </td>
                                        <td>
                                            <span class="badge bg-primary">{{ "%.2f"|format(metrics_data.accuracy) }}%</span>
                                        </td>
                                        <td>
                                            <span class="badge bg-success">{{ "%.2f"|format(metrics_data.precision) }}%</span>
                                        </td>
                                        <td>
                                            <span class="badge bg-warning">{{ "%.2f"|format(metrics_data.recall) }}%</span>
                                        </td>
                                        <td>
                                            <span class="badge bg-info">{{ "%.2f"|format(metrics_data.f1_score) }}%</span>
                                        </td>
                                    </tr>
                                    {% endfor %}
                                </tbody>
                            </table>
                        </div>

                        <!-- Confusion Matrices -->
                        <div class="row">
                            {% for algo_name, metrics_data in target_metrics.items() %}
                            <div class="col-lg-6 mb-4">
                                <div class="card">
                                    <div class="card-header bg-light">
                                        <h6 class="card-title mb-0">
                                            {{ algo_name.upper() }} Confusion Matrix
                                        </h6>
                                    </div>
                                    <div class="card-body">
                                        <canvas id="confusionMatrix_{{ target_name }}_{{ algo_name }}" width="300" height="300"></canvas>
                                    </div>
                                </div>
                            </div>
                            {% endfor %}
                        </div>

                        <!-- Detailed Classification Reports -->
                        <div class="accordion" id="accordion_{{ target_name }}">
                            {% for algo_name, metrics_data in target_metrics.items() %}
                            <div class="accordion-item">
                                <h2 class="accordion-header" id="heading_{{ target_name }}_{{ algo_name }}">
                                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" 
                                            data-bs-target="#collapse_{{ target_name }}_{{ algo_name }}">
                                        {{ algo_name.upper() }} Detailed Classification Report
                                    </button>
                                </h2>
                                <div id="collapse_{{ target_name }}_{{ algo_name }}" class="accordion-collapse collapse" 
                                     data-bs-parent="#accordion_{{ target_name }}">
                                    <div class="accordion-body">
                                        <div class="table-responsive">
                                            <table class="table table-sm">
                                                <thead>
                                                    <tr>
                                                        <th>Class</th>
                                                        <th>Precision</th>
                                                        <th>Recall</th>
                                                        <th>F1-Score</th>
                                                        <th>Support</th>
                                                    </tr>
                                                </thead>
                                                <tbody>
                                                    {% for class_name in metrics_data.class_names %}
                                                    {% if class_name in metrics_data.classification_report %}
                                                    <tr>
                                                        <td class="fw-bold">{{ class_name }}</td>
                                                        <td>{{ "%.3f"|format(metrics_data.classification_report[class_name]['precision']) }}</td>
                                                        <td>{{ "%.3f"|format(metrics_data.classification_report[class_name]['recall']) }}</td>
                                                        <td>{{ "%.3f"|format(metrics_data.classification_report[class_name]['f1-score']) }}</td>
                                                        <td>{{ metrics_data.classification_report[class_name]['support'] }}</td>
                                                    </tr>
                                                    {% endif %}
                                                    {% endfor %}
                                                </tbody>
                                            </table>
                                        </div>
                                    </div>
                                </div>
                            </div>
                            {% endfor %}
                        </div>
                    </div>
                </div>
                {% endfor %}

                <!-- Performance Comparison Chart -->
                <div class="card shadow-sm">
                    <div class="card-header bg-dark text-white">
                        <h5 class="card-title mb-0">
                            <i class="fas fa-chart-line"></i>
                            Algorithm Performance Comparison
                        </h5>
                    </div>
                    <div class="card-body">
                        <canvas id="performanceChart" height="100"></canvas>
                    </div>
                </div>
                
            {% else %}
                <div class="alert alert-warning" role="alert">
                    <i class="fas fa-exclamation-triangle"></i>
                    No performance metrics available. Please train models first from the <a href="{{ url_for('eda') }}" class="alert-link">EDA page</a>.
                </div>
            {% endif %}
        </div>
    </div>
</div>

<script>
// Render confusion matrices
{% if metrics %}
{% for target_name, target_metrics in metrics.items() %}
    {% for algo_name, metrics_data in target_metrics.items() %}
    (function() {
        const canvasId = 'confusionMatrix_{{ target_name }}_{{ algo_name }}';
        if (!canvasId || canvasId.includes('undefined')) return;
        const canvas = document.getElementById(canvasId);
        if (!canvas) return;
        const ctx = canvas.getContext('2d');
        
        const confusionMatrix = {{ metrics_data.confusion_matrix | tojson }};
        const classNames = {{ metrics_data.class_names | tojson }};
        
        // Simple confusion matrix visualization
        const cellSize = Math.min(canvas.width / confusionMatrix.length, canvas.height / confusionMatrix.length) * 0.8;
        const startX = (canvas.width - cellSize * confusionMatrix.length) / 2;
        const startY = (canvas.height - cellSize * confusionMatrix.length) / 2;
        
        // Find max value for normalization
        const maxValue = Math.max(...confusionMatrix.flat());
        
        for (let i = 0; i < confusionMatrix.length; i++) {
            for (let j = 0; j < confusionMatrix[i].length; j++) {
                const value = confusionMatrix[i][j];
                const intensity = value / maxValue;
                
                // Color based on intensity
                const color = `rgba(54, 162, 235, ${intensity})`;
                ctx.fillStyle = color;
                ctx.fillRect(startX + j * cellSize, startY + i * cellSize, cellSize, cellSize);
                
                // Border
                ctx.strokeStyle = '#333';
                ctx.lineWidth = 1;
                ctx.strokeRect(startX + j * cellSize, startY + i * cellSize, cellSize, cellSize);
                
                // Text
                ctx.fillStyle = intensity > 0.5 ? 'white' : 'black';
                ctx.font = '12px Arial';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'middle';
                ctx.fillText(value, 
                    startX + j * cellSize + cellSize / 2, 
                    startY + i * cellSize + cellSize / 2
                );
            }
        }
        
        // Labels
        ctx.fillStyle = 'black';
        ctx.font = '10px Arial';
        for (let i = 0; i < classNames.length; i++) {
            // Y-axis labels (true labels)
            ctx.textAlign = 'right';
            ctx.textBaseline = 'middle';
            ctx.fillText(classNames[i], startX - 5, startY + i * cellSize + cellSize / 2);
            
            // X-axis labels (predicted labels)
            ctx.textAlign = 'center';
            ctx.textBaseline = 'top';
            ctx.fillText(classNames[i], startX + i * cellSize + cellSize / 2, startY + confusionMatrix.length * cellSize + 5);
        }
    })();
    {% endfor %}
{% endfor %}

// Performance comparison chart
const performanceData = {
    {% for target_name, target_metrics in metrics.items() %}
    '{{ target_name }}': {
        {% for algo_name, metrics_data in target_metrics.items() %}
        '{{ algo_name }}': {
            accuracy: {{ metrics_data.accuracy }},
            precision: {{ metrics_data.precision }},
            recall: {{ metrics_data.recall }},
            f1_score: {{ metrics_data.f1_score }}
        },
        {% endfor %}
    },
    {% endfor %}
};

// Create performance comparison chart
const performanceChartElement = document.getElementById('performanceChart');
if (performanceChartElement && typeof Chart !== 'undefined') {
    const performanceCtx = performanceChartElement.getContext('2d');
    const algorithms = ['knn', 'svc', 'nb', 'STT'];
    const algoNames = {
        'knn': 'K-Nearest Neighbors',
        'svc': 'Support Vector Classifier', 
        'nb': 'Naive Bayes',
        'STT': 'STT Classifier'
    };

    const datasets = [];
    const colors = ['#FF6384', '#36A2EB', '#FFCE56', '#4BC0C0'];

    let colorIndex = 0;
    for (const target in performanceData) {
        const accuracyData = algorithms.map(algo => 
            performanceData[target][algo] ? performanceData[target][algo].accuracy : 0
        );
        
        datasets.push({
            label: target.replace('_', ' ').replace(/\b\w/g, l => l.toUpperCase()),
            data: accuracyData,
            backgroundColor: colors[colorIndex % colors.length],
            borderColor: colors[colorIndex % colors.length],
            borderWidth: 1
        });
        colorIndex++;
    }

    new Chart(performanceCtx, {
    type: 'bar',
    data: {
        labels: algorithms.map(algo => algoNames[algo]),
        datasets: datasets
    },
    options: {
        responsive: true,
        plugins: {
            title: {
                display: true,
                text: 'Accuracy Comparison Across All Models'
            }
        },
        scales: {
            y: {
                beginAtZero: true,
                max: 100,
                title: {
                    display: true,
                    text: 'Accuracy (%)'
                }
            }
        }
    }
    });
}
{% endif %}
</script>
{% endblock %}
